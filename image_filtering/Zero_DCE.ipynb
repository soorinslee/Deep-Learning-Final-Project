{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":389},"executionInfo":{"elapsed":36,"status":"error","timestamp":1650494978662,"user":{"displayName":"William Cui","userId":"09244100648444991382"},"user_tz":240},"id":"xoi2Zc3lSy8A","outputId":"6b6f43a2-8c57-4869-eade-66b9a4d6eec3"},"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_2097/3429714175.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## mount google drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m   \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m   \u001b[0mhome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhome\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m   \u001b[0mroot_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_env\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0mhome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HOME'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m   root_dir = _os.path.realpath(\n\u001b[0;32m---> 43\u001b[0;31m       _os.path.join(_os.environ['CLOUDSDK_CONFIG'], '../..'))\n\u001b[0m\u001b[1;32m     44\u001b[0m   \u001b[0minet_family\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'IPV4_ONLY'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m   \u001b[0mdev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/dev/fuse'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'CLOUDSDK_CONFIG'"]}],"source":["## mount google drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","import sys\n","import os\n","sys.path.append(os.path.abspath('/content/drive/MyDrive/image_filtering/'))\n","sys.path.append(os.path.abspath('/content/drive/MyDrive/image_filtering/Zero_DCE_model/Zero-DCE/Zero-DCE_code'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kBIVSakqSdRv"},"outputs":[],"source":["from __future__ import print_function, division\n","import torchvision\n","import torch\n","from skimage import io, transform\n","import numpy as np\n","from torchvision import transforms, utils\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import cv2\n","from math import log10, pi\n","import time\n","from google.colab import files\n","\n","import utils\n","from datasetsDCE import RedFlashDatasetDCE\n","from vgg import Vgg16\n","\n","from torchvision.utils import save_image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mIMLDqvxSdRx"},"outputs":[],"source":["class MFFNet(torch.nn.Module):\n","    def __init__(self):\n","        super(MFFNet, self).__init__()\n","        \n","        self.conv1 = ConvLayer(4, 32, kernel_size=9, stride=1)\n","        self.in1 = torch.nn.InstanceNorm2d(32, affine=True)\n","        self.conv2 = ConvLayer(32, 64, kernel_size=3, stride=2)\n","        self.in2 = torch.nn.InstanceNorm2d(64, affine=True)\n","        self.conv3 = ConvLayer(64, 128, kernel_size=3, stride=2)\n","        self.in3 = torch.nn.InstanceNorm2d(128, affine=True)\n","        # Residual layers\n","        self.res1 = ResidualBlock(128)\n","        self.res2 = ResidualBlock(128)\n","        self.res3 = ResidualBlock(128)\n","        self.res4 = ResidualBlock(128)\n","        self.res5 = ResidualBlock(128)\n","        self.res6 = ResidualBlock(128)\n","        self.res7 = ResidualBlock(128)\n","        self.res8 = ResidualBlock(128)\n","        self.res9 = ResidualBlock(128)\n","        self.res10 = ResidualBlock(128)\n","        self.res11 = ResidualBlock(128)\n","        self.res12 = ResidualBlock(128)\n","        self.res13 = ResidualBlock(128)\n","        self.res14 = ResidualBlock(128)\n","        self.res15 = ResidualBlock(128)\n","        self.res16 = ResidualBlock(128)\n","        \n","        self.deconv1 = UpsampleConvLayer(128*2, 64, kernel_size=3, stride=1, upsample=2)\n","        self.in4 = torch.nn.InstanceNorm2d(64, affine=True)\n","        self.deconv2 = UpsampleConvLayer(64*2, 32, kernel_size=3, stride=1, upsample=2)\n","        self.in5 = torch.nn.InstanceNorm2d(32, affine=True)\n","        self.deconv3 = ConvLayer(32*2, 3, kernel_size=9, stride=1)\n","\n","        self.relu = torch.nn.ReLU()\n","    \n","    def forward(self, X):\n","        o1 = self.relu(self.conv1(X))\n","        o2 = self.relu(self.conv2(o1))\n","        o3 = self.relu(self.conv3(o2))\n","\n","        y = self.res1(o3)\n","        y = self.res2(y)\n","        y = self.res3(y)\n","        y = self.res4(y)\n","        y = self.res5(y)\n","        y = self.res6(y)\n","        y = self.res7(y)\n","        y = self.res8(y)\n","        y = self.res9(y)\n","        y = self.res10(y)\n","        y = self.res11(y)\n","        y = self.res12(y)\n","        y = self.res13(y)\n","        y = self.res14(y)\n","        y = self.res15(y)\n","        y = self.res16(y)\n","        \n","        in1 = torch.cat( (y, o3), 1 )\n","        y = self.relu(self.deconv1(in1))\n","        in2 = torch.cat( (y, o2), 1 )\n","        y = self.relu(self.deconv2(in2))\n","        in3 = torch.cat( (y, o1), 1 )\n","        y = self.deconv3(in3)\n","        \n","        return y\n","\n","class ConvLayer(torch.nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, stride):\n","        super(ConvLayer, self).__init__()\n","        reflection_padding = kernel_size // 2\n","        self.reflection_pad = torch.nn.ReflectionPad2d(reflection_padding)\n","        self.conv2d = torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride)\n","    \n","    def forward(self, x):\n","        out = self.reflection_pad(x)\n","        out = self.conv2d(out)\n","        return out\n","\n","class ResidualBlock(torch.nn.Module):\n","    \n","    def __init__(self, channels):\n","        super(ResidualBlock, self).__init__()\n","        self.conv1 = ConvLayer(channels, channels, kernel_size=3, stride=1)\n","        self.in1 = torch.nn.InstanceNorm2d(channels, affine=True)\n","        self.conv2 = ConvLayer(channels, channels, kernel_size=3, stride=1)\n","        self.in2 = torch.nn.InstanceNorm2d(channels, affine=True)\n","        self.relu = torch.nn.ReLU()\n","    \n","    def forward(self, x):\n","        residual = x\n","        out = self.relu(self.conv1(x))\n","        out = self.conv2(out)\n","        out = out + residual\n","        return out\n","\n","\n","class UpsampleConvLayer(torch.nn.Module):\n","    \n","    def __init__(self, in_channels, out_channels, kernel_size, stride, upsample=None):\n","        super(UpsampleConvLayer, self).__init__()\n","        self.upsample = upsample\n","        reflection_padding = kernel_size // 2\n","        self.reflection_pad = torch.nn.ReflectionPad2d(reflection_padding)\n","        self.conv2d = torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride)\n","    \n","    def forward(self, x):\n","        x_in = x\n","        if self.upsample:\n","            x_in = torch.nn.functional.interpolate(x_in, mode='nearest', scale_factor=self.upsample)\n","        out = self.reflection_pad(x_in)\n","        out = self.conv2d(out)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["5858b24533c7437b8442eb17e52509a6","b4c8f651353c435b9c1b73f678af4256","ede9f9e295d64e40a4e3a98d9dcaa42e","921fe5c745f548bbb1ef4ebab9ebdace","5dc382c5cf58486eb49cae3fd480bbba","0cddd663943f461dbf322417b797640f","61d0082e405245d68147eeaa8e0bfa51","5605e6948abf4610baf73a95802425b4","3dda366db5164bc0a19a477c5e527a4e","3c4bd5140f874654a450b8a9713fee94","78273dc6ddcf421f8ca49d7a251e93e7"]},"executionInfo":{"elapsed":17482,"status":"ok","timestamp":1650494897651,"user":{"displayName":"Ankit Vishnu","userId":"15806096814679936632"},"user_tz":240},"id":"8OovYAgtXmNb","outputId":"a9337f25-9699-40e3-aba8-0f83a3bbde02"},"outputs":[{"output_type":"stream","name":"stdout","text":["1014 435\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/528M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5858b24533c7437b8442eb17e52509a6"}},"metadata":{}}],"source":["# redflash_dataset = RedFlashDataset('/content/drive/My Drive/image_filtering/Deep Learning Final Project/images', True)\n","redflash_dataset = RedFlashDatasetDCE('/content/drive/My Drive/image_filtering/Deep Learning Final Project/images', True)\n","train_size = int(0.7 * len(redflash_dataset.fileID))\n","val_size = len(redflash_dataset.fileID) - train_size\n","print(train_size, val_size)\n","train_dataset, val_dataset = torch.utils.data.random_split(redflash_dataset, [train_size, val_size])\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=16,\n","                                           shuffle=True,\n","                                           num_workers=0)\n","\n","val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n","                                           batch_size=16,\n","                                           shuffle=True,\n","                                           num_workers=0)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","imageFilter = MFFNet()\n","model_name = 'MFF-net'\n","imageFilter.load_state_dict(torch.load(f'/content/drive/My Drive/image_filtering/MFF-net-wc.ckpt'))\n","imageFilter = imageFilter.to(device).float()\n","\n","# Initializing VGG16 model for perceptual loss\n","VGG = Vgg16(requires_grad=False)\n","VGG = VGG.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8RLxPcEKYWih","outputId":"41d032fb-b14f-4abc-a5ff-4c01d29c7514"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"]}],"source":["num_epochs = 600\n","learning_rate = 1e-5\n","\n","criterion_img = nn.MSELoss()\n","criterion_vgg = nn.MSELoss()\n","\n","optimizer = torch.optim.Adam(imageFilter.parameters(), lr=learning_rate)\n","total_step = len(train_loader)\n","\n","start_epoch = 21\n","\n","if start_epoch < 300:\n","  learning_rate = 1e-4\n","else: \n","  learning_rate = 1e-5\n","\n","start_time = time.time()\n","for epoch in range(start_epoch, num_epochs):\n","    loss_tol = 0\n","    loss_tol_vgg  = 0\n","    loss_tol_l2   = 0\n","\n","    if epoch > 0 and epoch % 10 == 0:\n","      torch.save(imageFilter.state_dict(), f'/content/drive/My Drive/image_filtering/MFF-net-wc.ckpt')\n","      files.download('/content/drive/My Drive/image_filtering/MFF-net-wc.ckpt')\n","    \n","    if epoch == 300:\n","        learning_rate = 1e-5\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = learning_rate\n","        \n","    if epoch == 600:\n","        learning_rate = 1e-6\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = learning_rate\n","    \n","    for i, im in enumerate(train_loader):\n","        inputs = im[0].float().to(device)\n","        target = im[1].float().to(device)\n","        \n","        outputs = imageFilter(inputs)\n","        \n","        loss_l2 = criterion_img( outputs, target )\n","        \n","        outputs_n = utils.normalize_ImageNet_stats(outputs)\n","        target_n  = utils.normalize_ImageNet_stats(target)\n","        \n","        feature_o = VGG(outputs_n, 3)\n","        feature_t = VGG(target_n, 3)\n","        VGG_loss = []\n","        for l in range(3+1):\n","            VGG_loss.append( criterion_vgg(feature_o[l], feature_t[l]) )\n","        \n","        loss_vgg = sum(VGG_loss)\n","        loss = loss_l2 + 0.01*loss_vgg\n","    \n","        loss_tol += loss.item()\n","        \n","        loss_tol_vgg  += loss_vgg\n","        loss_tol_l2   += loss_l2\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","    \n","    print ( 'Epoch [{}/{}], Training Loss: {:.4f}, vgg Loss: {:.4f}, L2 Loss: {:.4f}' .format(epoch+1, num_epochs, loss_tol, loss_tol_vgg, loss_tol_l2) )\n","\n","print(\"--- %0.4f seconds ---\" % (time.time() - start_time)) \n","torch.save(imageFilter.state_dict(), f'/content/drive/My Drive/image_filtering/MFF-net-wc.ckpt')\n","files.download('/content/drive/My Drive/image_filtering/MFF-net-wc.ckpt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"phM9M4VSSdR0"},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","imageFil = MFFNet()\n","\n","model_name = 'MFF-net'\n","imageFil.load_state_dict( torch.load('/content/drive/My Drive/image_filtering/%s.ckpt'%(model_name)) )\n","imageFil = imageFil.to(device).float()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"efQekM26SdR0"},"outputs":[],"source":["data_root = '/content/drive/My Drive/image_filtering/test'\n","out_root = '/content/drive/My Drive/image_filtering/output'\n","if not os.path.exists(out_root):\n","    os.mkdir(out_root)\n","\n","for seq in range(1,6):\n","    # input rgb image is obtained from demosaicing the raw (no other manipulation)\n","    # saved in 16-bit TIFF image\n","    file = ('rgb_%s.tiff' % (seq) )\n","    filename = os.path.join( data_root, file )\n","    inputs = io.imread(filename) / 65535\n","\n","    file = ('guide_%s.bmp' % (seq) )\n","    filename = os.path.join( data_root, file )\n","    guided = io.imread(filename) / 255\n","\n","    guided = guided[:,:,0]+guided[:,:,1]+guided[:,:,2]\n","    inputs = (inputs*80)**0.4\n","    inputs = np.concatenate((inputs, guided[:,:,None]), 2)\n","    inputs = np.transpose(inputs,(2,0,1))\n","    inputs = torch.from_numpy(inputs)\n","    inputs = inputs[None,:,:,:].float()\n","\n","    with torch.no_grad():\n","        inputs = inputs.to(device) \n","        outputs = imageFil(inputs)\n","    outputs[outputs>1] = 1\n","    outputs[outputs<0] = 0    \n","\n","    # the parameter for color balance and brightness should be tuned for different scenes\n","    outputs[0,0,:,:] = outputs[0,0,:,:]*1.1*1.5\n","    outputs[0,1,:,:] = outputs[0,1,:,:]*1*1.5\n","    outputs[0,2,:,:] = outputs[0,2,:,:]*1.5*1.5\n","\n","    save_image(outputs[0,:,:,:], '%s/out_%s.png' % (out_root, seq))\n","    save_image(inputs[0,0:3,:,:], '%s/inp_%s.png' % (out_root, seq))"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"CillWui.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"5858b24533c7437b8442eb17e52509a6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b4c8f651353c435b9c1b73f678af4256","IPY_MODEL_ede9f9e295d64e40a4e3a98d9dcaa42e","IPY_MODEL_921fe5c745f548bbb1ef4ebab9ebdace"],"layout":"IPY_MODEL_5dc382c5cf58486eb49cae3fd480bbba"}},"b4c8f651353c435b9c1b73f678af4256":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0cddd663943f461dbf322417b797640f","placeholder":"​","style":"IPY_MODEL_61d0082e405245d68147eeaa8e0bfa51","value":"100%"}},"ede9f9e295d64e40a4e3a98d9dcaa42e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5605e6948abf4610baf73a95802425b4","max":553433881,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3dda366db5164bc0a19a477c5e527a4e","value":553433881}},"921fe5c745f548bbb1ef4ebab9ebdace":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c4bd5140f874654a450b8a9713fee94","placeholder":"​","style":"IPY_MODEL_78273dc6ddcf421f8ca49d7a251e93e7","value":" 528M/528M [00:04&lt;00:00, 140MB/s]"}},"5dc382c5cf58486eb49cae3fd480bbba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0cddd663943f461dbf322417b797640f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61d0082e405245d68147eeaa8e0bfa51":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5605e6948abf4610baf73a95802425b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3dda366db5164bc0a19a477c5e527a4e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3c4bd5140f874654a450b8a9713fee94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78273dc6ddcf421f8ca49d7a251e93e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}