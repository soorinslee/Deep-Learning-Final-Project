{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"BXxO5TPh8UwS","executionInfo":{"status":"ok","timestamp":1650509500100,"user_tz":240,"elapsed":10153,"user":{"displayName":"Ankit Vishnu","userId":"15806096814679936632"}}},"outputs":[],"source":["from __future__ import print_function, division\n","import os\n","import torchvision\n","import torch\n","from skimage import io, transform\n","import numpy as np\n","from torchvision import transforms, utils\n","import torch.nn as nn\n","import cv2\n","\n","from torchvision.utils import save_image"]},{"cell_type":"code","source":["## mount google drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","import sys\n","import os\n","sys.path.append(os.path.abspath('/content/drive/My Drive/image_filtering/'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nVVRv0g58z16","executionInfo":{"status":"ok","timestamp":1650509517763,"user_tz":240,"elapsed":16620,"user":{"displayName":"Ankit Vishnu","userId":"15806096814679936632"}},"outputId":"50d81e69-ab99-47b2-9449-f58feebb527a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"xWc_lD038UwV","executionInfo":{"status":"ok","timestamp":1650509520151,"user_tz":240,"elapsed":274,"user":{"displayName":"Ankit Vishnu","userId":"15806096814679936632"}}},"outputs":[],"source":["class MFFNet(torch.nn.Module):\n","    def __init__(self):\n","        super(MFFNet, self).__init__()\n","        \n","        self.conv1 = ConvLayer(4, 32, kernel_size=9, stride=1)\n","        self.in1 = torch.nn.InstanceNorm2d(32, affine=True)\n","        self.conv2 = ConvLayer(32, 64, kernel_size=3, stride=2)\n","        self.in2 = torch.nn.InstanceNorm2d(64, affine=True)\n","        self.conv3 = ConvLayer(64, 128, kernel_size=3, stride=2)\n","        self.in3 = torch.nn.InstanceNorm2d(128, affine=True)\n","        # Residual layers\n","        self.res1 = ResidualBlock(128)\n","        self.res2 = ResidualBlock(128)\n","        self.res3 = ResidualBlock(128)\n","        self.res4 = ResidualBlock(128)\n","        self.res5 = ResidualBlock(128)\n","        self.res6 = ResidualBlock(128)\n","        self.res7 = ResidualBlock(128)\n","        self.res8 = ResidualBlock(128)\n","        self.res9 = ResidualBlock(128)\n","        self.res10 = ResidualBlock(128)\n","        self.res11 = ResidualBlock(128)\n","        self.res12 = ResidualBlock(128)\n","        self.res13 = ResidualBlock(128)\n","        self.res14 = ResidualBlock(128)\n","        self.res15 = ResidualBlock(128)\n","        self.res16 = ResidualBlock(128)\n","        \n","        self.deconv1 = UpsampleConvLayer(128*2, 64, kernel_size=3, stride=1, upsample=2)\n","        self.in4 = torch.nn.InstanceNorm2d(64, affine=True)\n","        self.deconv2 = UpsampleConvLayer(64*2, 32, kernel_size=3, stride=1, upsample=2)\n","        self.in5 = torch.nn.InstanceNorm2d(32, affine=True)\n","        self.deconv3 = ConvLayer(32*2, 3, kernel_size=9, stride=1)\n","\n","        self.relu = torch.nn.ReLU()\n","    \n","    def forward(self, X):\n","        o1 = self.relu(self.conv1(X))\n","        o2 = self.relu(self.conv2(o1))\n","        o3 = self.relu(self.conv3(o2))\n","\n","        y = self.res1(o3)\n","        y = self.res2(y)\n","        y = self.res3(y)\n","        y = self.res4(y)\n","        y = self.res5(y)\n","        y = self.res6(y)\n","        y = self.res7(y)\n","        y = self.res8(y)\n","        y = self.res9(y)\n","        y = self.res10(y)\n","        y = self.res11(y)\n","        y = self.res12(y)\n","        y = self.res13(y)\n","        y = self.res14(y)\n","        y = self.res15(y)\n","        y = self.res16(y)\n","        \n","        in1 = torch.cat( (y, o3), 1 )\n","        y = self.relu(self.deconv1(in1))\n","        in2 = torch.cat( (y, o2), 1 )\n","        y = self.relu(self.deconv2(in2))\n","        in3 = torch.cat( (y, o1), 1 )\n","        y = self.deconv3(in3)\n","        \n","        return y\n","\n","class ConvLayer(torch.nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, stride):\n","        super(ConvLayer, self).__init__()\n","        reflection_padding = kernel_size // 2\n","        self.reflection_pad = torch.nn.ReflectionPad2d(reflection_padding)\n","        self.conv2d = torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride)\n","    \n","    def forward(self, x):\n","        out = self.reflection_pad(x)\n","        out = self.conv2d(out)\n","        return out\n","\n","class ResidualBlock(torch.nn.Module):\n","    \n","    def __init__(self, channels):\n","        super(ResidualBlock, self).__init__()\n","        self.conv1 = ConvLayer(channels, channels, kernel_size=3, stride=1)\n","        self.in1 = torch.nn.InstanceNorm2d(channels, affine=True)\n","        self.conv2 = ConvLayer(channels, channels, kernel_size=3, stride=1)\n","        self.in2 = torch.nn.InstanceNorm2d(channels, affine=True)\n","        self.relu = torch.nn.ReLU()\n","    \n","    def forward(self, x):\n","        residual = x\n","        out = self.relu(self.conv1(x))\n","        out = self.conv2(out)\n","        out = out + residual\n","        return out\n","\n","\n","class UpsampleConvLayer(torch.nn.Module):\n","    \n","    def __init__(self, in_channels, out_channels, kernel_size, stride, upsample=None):\n","        super(UpsampleConvLayer, self).__init__()\n","        self.upsample = upsample\n","        reflection_padding = kernel_size // 2\n","        self.reflection_pad = torch.nn.ReflectionPad2d(reflection_padding)\n","        self.conv2d = torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride)\n","    \n","    def forward(self, x):\n","        x_in = x\n","        if self.upsample:\n","            x_in = torch.nn.functional.interpolate(x_in, mode='nearest', scale_factor=self.upsample)\n","        out = self.reflection_pad(x_in)\n","        out = self.conv2d(out)\n","        return out"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"TvhNjwav8UwW","executionInfo":{"status":"ok","timestamp":1650510201063,"user_tz":240,"elapsed":3028,"user":{"displayName":"Ankit Vishnu","userId":"15806096814679936632"}}},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","imageFilter = MFFNet()\n","imageFilter_inv = MFFNet()\n","imageFilter_sr = MFFNet()\n","imageFilter_wc = MFFNet()\n","\n","model_name = 'MFF-net-nd'\n","model_name_inv = 'MFF-net3'\n","model_name_sr = 'MFF-net-sr'\n","model_name_wc = 'MFF-net-wc'\n","\n","imageFilter.load_state_dict( torch.load('/content/drive/My Drive/image_filtering/%s.ckpt'%(model_name)) )\n","imageFilter_inv.load_state_dict( torch.load('/content/drive/My Drive/image_filtering/%s.ckpt'%(model_name_inv)) )\n","imageFilter_sr.load_state_dict( torch.load('/content/drive/My Drive/image_filtering/%s.ckpt'%(model_name_sr)) )\n","imageFilter_wc.load_state_dict( torch.load('/content/drive/My Drive/image_filtering/%s.ckpt'%(model_name_wc)) )\n","\n","imageFilter = imageFilter.to(device).float()\n","imageFilter_inv = imageFilter_inv.to(device).float()\n","imageFilter_sr = imageFilter_sr.to(device).float()\n","imageFilter_wc = imageFilter_wc.to(device).float()"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"8-8GAcqh8UwX","executionInfo":{"status":"ok","timestamp":1650510335750,"user_tz":240,"elapsed":11648,"user":{"displayName":"Ankit Vishnu","userId":"15806096814679936632"}}},"outputs":[],"source":["data_root = '/content/drive/My Drive/image_filtering/test'\n","out_root = '/content/drive/My Drive/image_filtering/output/'\n","if not os.path.exists(out_root):\n","    os.mkdir(out_root)\n","\n","for seq in range(1,6):\n","    # input rgb image is obtained from demosaicing the raw (no other manipulation)\n","    # saved in 16-bit TIFF image\n","    file = ('rgb_%s.tiff' % (seq) )\n","    filename = os.path.join( data_root, file )\n","    inputs = io.imread(filename) / 65535\n","\n","    file = ('guide_%s.bmp' % (seq) )\n","    filename = os.path.join( data_root, file )\n","    guided = io.imread(filename) / 255\n","\n","    guided = guided[:,:,0]+guided[:,:,1]+guided[:,:,2]\n","    inputs = (inputs*80)**0.4\n","    inputs = np.concatenate((inputs, guided[:,:,None]), 2)\n","    inputs = np.transpose(inputs,(2,0,1))\n","    inputs = torch.from_numpy(inputs)\n","    inputs = inputs[None,:,:,:].float()\n","\n","    with torch.no_grad():\n","        inputs = inputs.to(device) \n","        outputs = imageFilter_wc(inputs)\n","    outputs[outputs>1] = 1\n","    outputs[outputs<0] = 0    \n","\n","    # the parameter for color balance and brightness should be tuned for different scenes\n","    outputs[0,0,:,:] = outputs[0,0,:,:]*1.1*1.5\n","    outputs[0,1,:,:] = outputs[0,1,:,:]*1*1.5\n","    outputs[0,2,:,:] = outputs[0,2,:,:]*1.5*1.5\n","\n","    save_image(outputs[0,:,:,:], '%s/out_%s_model_wc.png' % (out_root, seq))\n","    # save_image(inputs[0,0:3,:,:], '%s/inp_%s_model1.png' % (out_root, seq))"]},{"cell_type":"code","source":["import cv2\n","from matplotlib import pyplot as plt\n","  \n","# create figure\n","fig = plt.figure(figsize=(20, 15))\n","  \n","# setting values to rows and column variables\n","rows = 3\n","columns = 3\n","  \n","# reading images\n","Image_dl = cv2.imread(\"/content/drive/My Drive/image_filtering/output/inp_6.png\")\n","Image_guide = cv2.imread(\"/content/drive/My Drive/image_filtering/test/guide_6.bmp\")\n","Image_guide = cv2.cvtColor(Image_guide, cv2.COLOR_BGR2RGB)\n","Image_base = cv2.imread(\"/content/drive/My Drive/image_filtering/output/out_6_model_base.png\")\n","Image_inv = cv2.imread(\"/content/drive/My Drive/image_filtering/output/out_6_model_inv.png\")\n","Image_sr = cv2.imread(\"/content/drive/My Drive/image_filtering/output/out_6_model_sr.png\")\n","Image_wc = cv2.imread(\"/content/drive/My Drive/image_filtering/output/out_6_model_wc.png\")\n","Image_true = cv2.imread(\"/content/drive/My Drive/image_filtering/test/gt_6.bmp\")\n","\n","# Adds a subplot at the 1st position\n","fig.add_subplot(rows, columns, 1)\n","\n","# showing image\n","plt.imshow(Image_dl)\n","plt.axis('off')\n","plt.title(\"Lightened Demosaiced Input Image\")\n","  \n","# Adds a subplot at the 2nd position\n","fig.add_subplot(rows, columns, 2)\n","  \n","# showing image\n","plt.imshow(Image_guide)\n","plt.axis('off')\n","plt.title(\"Guide Red Image\")\n","\n","# Adds a subplot at the 3rd position\n","fig.add_subplot(rows, columns, 3)\n","  \n","# showing image\n","plt.imshow(Image_base)\n","plt.axis('off')\n","plt.title(\"DRF output\")\n","\n","# Adds a subplot at the 4th position\n","fig.add_subplot(rows, columns, 4)\n","  \n","# showing image\n","plt.imshow(Image_inv)\n","plt.axis('off')\n","plt.title(\"InvDN DRF Output\")\n","\n","# Adds a subplot at the 5th position\n","fig.add_subplot(rows, columns, 5)\n","  \n","# showing image\n","plt.imshow(Image_sr)\n","plt.axis('off')\n","plt.title(\"RUAS DRF Output\")\n","\n","# Adds a subplot at the 6th position\n","fig.add_subplot(rows, columns, 6)\n","  \n","# showing image\n","plt.imshow(Image_wc)\n","plt.axis('off')\n","plt.title(\"Zero-DCE DRF Output\")\n","  \n","# Adds a subplot at the 5th position\n","fig.add_subplot(rows, columns, 7)\n","  \n","# showing image\n","plt.imshow(Image_true)\n","plt.axis('off')\n","plt.title(\"Ground Truth\")\n","\n","plt.savefig('Image6_comp.png')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":258},"id":"gtiNdkwv_3kZ","executionInfo":{"status":"error","timestamp":1650511592929,"user_tz":240,"elapsed":140,"user":{"displayName":"Ankit Vishnu","userId":"15806096814679936632"}},"outputId":"fa2b70ff-16b2-447a-98b5-476cdcd26d11"},"execution_count":21,"outputs":[{"output_type":"error","ename":"error","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-a4569c40733c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mImage_dl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/image_filtering/output/inp_6.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mImage_guide\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/image_filtering/test/guide_6.bmp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mImage_guide\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage_guide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mImage_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/image_filtering/output/out_6_model_base.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mImage_inv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/image_filtering/output/out_6_model_inv.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1440x1080 with 0 Axes>"]},"metadata":{}}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"evaluate.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}